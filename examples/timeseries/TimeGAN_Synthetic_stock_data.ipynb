{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J9XZAsnQjCVz"
      },
      "outputs": [],
      "source": [
        "# Note: You can select between running the Notebook on \"CPU\" or \"GPU\"\n",
        "# Click \"Runtime > Change Runtime time\" and set \"GPU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FGzo4LZqjOWA"
      },
      "outputs": [],
      "source": [
        "#Uncomment to install ydata-synthetic lib\n",
        "! pip install ydata-synthetic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G1BWdpdHWkFu"
      },
      "source": [
        "# Time Series synthetic data generation with TimeGAN\n",
        "\n",
        "- TimeGAN - Implemented accordingly with the [paper](https://papers.nips.cc/paper/8789-time-series-generative-adversarial-networks)\n",
        "- This notebook is an example of how TimeGan can be used to generate synthetic time-series data.\n",
        "\n",
        "## Dataset and imports\n",
        "\n",
        "- The data used in this notebook was downloaded from [Yahoo finance](https://finance.yahoo.com/quote/GOOG/history?p=GOOG) and includes:\n",
        "    - **6 variables** - Open, High, Low, Close, Adj Close, Volume\n",
        "    - **1022 events** registered between the period of 1 January 2017 - 24 January 2021.\n",
        "    - The data was processed using a MinMaxScaler (all the variables were numeric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aEIlLGWpjtWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "2de2230e-d763-4d59-dd88-c58baedaf70c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ydata_synthetic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ab1db0c0e4f9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mydata_synthetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthesizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelParameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainParameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mydata_synthetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprocessed_stock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mydata_synthetic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynthesizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeseries\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimeSeriesSynthesizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ydata_synthetic'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# Importing the required libs for the exercise\n",
        "\n",
        "from os import path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ydata_synthetic.synthesizers import ModelParameters, TrainParameters\n",
        "from ydata_synthetic.preprocessing.timeseries import processed_stock\n",
        "from ydata_synthetic.synthesizers.timeseries import TimeSeriesSynthesizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "crMDw9AOWkFv"
      },
      "source": [
        "## Define Model hyperparameters\n",
        "\n",
        "**Networks:**\n",
        "- Generator\n",
        "- Discriminator\n",
        "- Embedder\n",
        "- Recovery Network\n",
        "\n",
        "TimeGAN is a Generative model based on RNN networks. In this package the implemented version follows a very simple architecture that is shared by the four elements of the GAN.\n",
        "\n",
        "Similarly to other parameters, the architectures of each element should be optimized and tailored to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "plCXvoJiWkFv"
      },
      "outputs": [],
      "source": [
        "# Specific to TimeGANs\n",
        "seq_len = 24\n",
        "n_seq = 6\n",
        "hidden_dim = 24\n",
        "gamma = 1\n",
        "\n",
        "noise_dim = 32\n",
        "dim = 128\n",
        "batch_size = 128\n",
        "\n",
        "log_step = 100\n",
        "learning_rate = 5e-4\n",
        "# For quick prototyping\n",
        "# epochs=50000\n",
        "epochs = 10\n",
        "\n",
        "gan_args = ModelParameters(\n",
        "    batch_size=batch_size, lr=learning_rate, noise_dim=noise_dim, layers_dim=dim\n",
        ")\n",
        "\n",
        "train_args = TrainParameters(\n",
        "    epochs=epochs, sequence_length=seq_len, number_sequences=n_seq\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGRoYLfCWkFv"
      },
      "source": [
        "## The data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "OrB1rCV8WkFv"
      },
      "outputs": [],
      "source": [
        "data_path = '../../data/stock_data.csv'\n",
        "stock_data = pd.read_csv(data_path)\n",
        "cols = list(stock_data.columns)\n",
        "print(stock_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3vRjO7pqWkFw"
      },
      "source": [
        "## Training the TimeGAN synthetizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "RMOXHx9xWkFw"
      },
      "outputs": [],
      "source": [
        "if path.exists(\"synthesizer_stock.pkl\"):\n",
        "    synth = TimeSeriesSynthesizer.load(\"synthesizer_stock.pkl\")\n",
        "else:\n",
        "    synth = TimeSeriesSynthesizer(modelname=\"timegan\", model_parameters=gan_args)\n",
        "    synth.fit(stock_data, train_args, num_cols=cols)\n",
        "    synth.save(\"synthesizer_stock.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "kzL_pIE1WkFw"
      },
      "source": [
        "### The generated synthetic stock data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "w_sAXHuiWkFx"
      },
      "outputs": [],
      "source": [
        "stock_data_blocks = processed_stock(path=data_path, seq_len=seq_len)\n",
        "synth_data = np.asarray(synth.sample(len(stock_data_blocks)))\n",
        "print(synth_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6jMwANZsWkFx"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Plotting some generated samples. Both Synthetic and Original data are still standartized with values between [0,1]\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 10))\n",
        "axes=axes.flatten()\n",
        "\n",
        "time = list(range(1,25))\n",
        "obs = np.random.randint(len(stock_data_blocks))\n",
        "\n",
        "for j, col in enumerate(cols):\n",
        "    df = pd.DataFrame({'Real': stock_data_blocks[obs][:, j],\n",
        "                   'Synthetic': synth_data[obs][:, j]})\n",
        "    df.plot(ax=axes[j],\n",
        "            title = col,\n",
        "            secondary_y='Synthetic data', style=['-', '--'])\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "OZYQ0CjYWkFx"
      },
      "source": [
        "#### Evaluation of the generated synthetic data (PCA and TSNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "1QWz32x5WkFx"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "sample_size = 250\n",
        "idx = np.random.permutation(len(stock_data_blocks))[:sample_size]\n",
        "\n",
        "real_sample = np.asarray(stock_data_blocks)[idx]\n",
        "synthetic_sample = np.asarray(synth_data)[idx]\n",
        "\n",
        "#for the purpose of comparision we need the data to be 2-Dimensional. For that reason we are going to use only two componentes for both the PCA and TSNE.\n",
        "synth_data_reduced = real_sample.reshape(-1, seq_len)\n",
        "stock_data_reduced = np.asarray(synthetic_sample).reshape(-1,seq_len)\n",
        "\n",
        "n_components = 2\n",
        "pca = PCA(n_components=n_components)\n",
        "tsne = TSNE(n_components=n_components, n_iter=300)\n",
        "\n",
        "#The fit of the methods must be done only using the real sequential data\n",
        "pca.fit(stock_data_reduced)\n",
        "\n",
        "pca_real = pd.DataFrame(pca.transform(stock_data_reduced))\n",
        "pca_synth = pd.DataFrame(pca.transform(synth_data_reduced))\n",
        "\n",
        "data_reduced = np.concatenate((stock_data_reduced, synth_data_reduced), axis=0)\n",
        "tsne_results = pd.DataFrame(tsne.fit_transform(data_reduced))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "mKqRhdkHWkFx"
      },
      "outputs": [],
      "source": [
        "#The scatter plots for PCA and TSNE methods\n",
        "import matplotlib.gridspec as gridspec\n",
        "fig = plt.figure(constrained_layout=True, figsize=(20,10))\n",
        "spec = gridspec.GridSpec(ncols=2, nrows=1, figure=fig)\n",
        "\n",
        "#TSNE scatter plot\n",
        "ax = fig.add_subplot(spec[0,0])\n",
        "ax.set_title('PCA results',\n",
        "             fontsize=20,\n",
        "             color='red',\n",
        "             pad=10)\n",
        "\n",
        "#PCA scatter plot\n",
        "plt.scatter(pca_real.iloc[:, 0].values, pca_real.iloc[:,1].values,\n",
        "            c='black', alpha=0.2, label='Original')\n",
        "plt.scatter(pca_synth.iloc[:,0], pca_synth.iloc[:,1],\n",
        "            c='red', alpha=0.2, label='Synthetic')\n",
        "ax.legend()\n",
        "\n",
        "ax2 = fig.add_subplot(spec[0,1])\n",
        "ax2.set_title('TSNE results',\n",
        "              fontsize=20,\n",
        "              color='red',\n",
        "              pad=10)\n",
        "\n",
        "plt.scatter(tsne_results.iloc[:sample_size, 0].values, tsne_results.iloc[:sample_size,1].values,\n",
        "            c='black', alpha=0.2, label='Original')\n",
        "plt.scatter(tsne_results.iloc[sample_size:,0], tsne_results.iloc[sample_size:,1],\n",
        "            c='red', alpha=0.2, label='Synthetic')\n",
        "\n",
        "ax2.legend()\n",
        "\n",
        "fig.suptitle('Validating synthetic vs real data diversity and distributions',\n",
        "             fontsize=16,\n",
        "             color='grey')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "3zCNqpFjWkFx"
      },
      "source": [
        "#### Train synthetic test real (TSTR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "S2lB9RXkWkFx"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Input, Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import GRU, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "\n",
        "#First implement a simple RNN model for prediction\n",
        "def RNN_regression(units):\n",
        "    opt = Adam(name='AdamOpt')\n",
        "    loss = MeanAbsoluteError(name='MAE')\n",
        "    model = Sequential()\n",
        "    model.add(GRU(units=units,\n",
        "                  name=f'RNN_1'))\n",
        "    model.add(Dense(units=6,\n",
        "                    activation='sigmoid',\n",
        "                    name='OUT'))\n",
        "    model.compile(optimizer=opt, loss=loss)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lWfXUzL8WkFy"
      },
      "outputs": [],
      "source": [
        "#Prepare the dataset for the regression model\n",
        "stock_data=np.asarray(stock_data_blocks)\n",
        "synth_data = synth_data[:len(stock_data)]\n",
        "n_events = len(stock_data)\n",
        "\n",
        "#Split data on train and test\n",
        "idx = np.arange(n_events)\n",
        "n_train = int(.75*n_events)\n",
        "train_idx = idx[:n_train]\n",
        "test_idx = idx[n_train:]\n",
        "\n",
        "#Define the X for synthetic and real data\n",
        "X_stock_train = stock_data[train_idx, :seq_len-1, :]\n",
        "X_synth_train = synth_data[train_idx, :seq_len-1, :]\n",
        "\n",
        "X_stock_test = stock_data[test_idx, :seq_len-1, :]\n",
        "y_stock_test = stock_data[test_idx, -1, :]\n",
        "\n",
        "#Define the y for synthetic and real datasets\n",
        "y_stock_train = stock_data[train_idx, -1, :]\n",
        "y_synth_train = synth_data[train_idx, -1, :]\n",
        "\n",
        "print('Synthetic X train: {}'.format(X_synth_train.shape))\n",
        "print('Real X train: {}'.format(X_stock_train.shape))\n",
        "\n",
        "print('Synthetic y train: {}'.format(y_synth_train.shape))\n",
        "print('Real y train: {}'.format(y_stock_train.shape))\n",
        "\n",
        "print('Real X test: {}'.format(X_stock_test.shape))\n",
        "print('Real y test: {}'.format(y_stock_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "-3MnoDn9WkFy"
      },
      "outputs": [],
      "source": [
        "#Training the model with the real train data\n",
        "ts_real = RNN_regression(12)\n",
        "early_stopping = EarlyStopping(monitor='val_loss')\n",
        "\n",
        "real_train = ts_real.fit(x=X_stock_train,\n",
        "                          y=y_stock_train,\n",
        "                          validation_data=(X_stock_test, y_stock_test),\n",
        "                          epochs=200,\n",
        "                          batch_size=128,\n",
        "                          callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5WR4OUR_WkFy"
      },
      "outputs": [],
      "source": [
        "#Training the model with the synthetic data\n",
        "ts_synth = RNN_regression(12)\n",
        "synth_train = ts_synth.fit(x=X_synth_train,\n",
        "                          y=y_synth_train,\n",
        "                          validation_data=(X_stock_test, y_stock_test),\n",
        "                          epochs=200,\n",
        "                          batch_size=128,\n",
        "                          callbacks=[early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "9Y7uOEK2WkFy"
      },
      "outputs": [],
      "source": [
        "#Summarize the metrics here as a pandas dataframe\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_log_error\n",
        "real_predictions = ts_real.predict(X_stock_test)\n",
        "synth_predictions = ts_synth.predict(X_stock_test)\n",
        "\n",
        "metrics_dict = {'r2': [r2_score(y_stock_test, real_predictions),\n",
        "                       r2_score(y_stock_test, synth_predictions)],\n",
        "                'MAE': [mean_absolute_error(y_stock_test, real_predictions),\n",
        "                        mean_absolute_error(y_stock_test, synth_predictions)],\n",
        "                'MRLE': [mean_squared_log_error(y_stock_test, real_predictions),\n",
        "                         mean_squared_log_error(y_stock_test, synth_predictions)]}\n",
        "\n",
        "results = pd.DataFrame(metrics_dict, index=['Real', 'Synthetic'])\n",
        "\n",
        "results"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "TimeGAN - Synthetic stock data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}